#!/usr/bin/env python3
"""
SEO Verification Script for OH-SCIPE Website
Checks if all SEO elements are properly implemented
"""

import os
import re
from pathlib import Path

def check_file_seo(filepath):
    """Check SEO elements in an HTML file"""
    issues = []
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Check for required meta tags
    if '<title>' not in content or 'OH-SCIPE</title>' == content.count('<title>'):
        issues.append("Missing or generic title tag")
    
    if 'name="description"' not in content:
        issues.append("Missing meta description")
    
    if 'name="keywords"' not in content:
        issues.append("Missing meta keywords")
    
    if 'rel="canonical"' not in content:
        issues.append("Missing canonical URL")
    
    # Check for Open Graph tags
    if 'property="og:title"' not in content:
        issues.append("Missing Open Graph title")
    
    if 'property="og:description"' not in content:
        issues.append("Missing Open Graph description")
    
    # Check for Twitter Card tags
    if 'name="twitter:card"' not in content:
        issues.append("Missing Twitter Card")
    
    # Check for structured data
    if 'application/ld+json' not in content:
        issues.append("Missing structured data (JSON-LD)")
    
    # Check for proper heading hierarchy
    if '<h1' not in content:
        issues.append("Missing H1 heading")
    
    # Check for alt attributes on images
    img_pattern = r'<img[^>]+>'
    images = re.findall(img_pattern, content)
    for img in images:
        if 'alt=""' in img or 'alt' not in img:
            issues.append(f"Image without proper alt text")
            break
    
    return issues

def main():
    """Main verification function"""
    print("=" * 70)
    print("OH-SCIPE Website SEO Verification")
    print("=" * 70)
    print()
    
    # Check robots.txt
    print("‚úì Checking robots.txt...")
    if os.path.exists('robots.txt'):
        print("  ‚úÖ robots.txt exists")
        with open('robots.txt', 'r') as f:
            content = f.read()
            if 'Sitemap:' in content and 'User-agent:' in content:
                print("  ‚úÖ robots.txt properly configured")
            else:
                print("  ‚ö†Ô∏è  robots.txt may need configuration")
    else:
        print("  ‚ùå robots.txt missing")
    
    print()
    
    # Check sitemap.xml
    print("‚úì Checking sitemap.xml...")
    if os.path.exists('sitemap.xml'):
        print("  ‚úÖ sitemap.xml exists")
        with open('sitemap.xml', 'r') as f:
            content = f.read()
            url_count = content.count('<url>')
            print(f"  ‚úÖ Contains {url_count} URLs")
    else:
        print("  ‚ùå sitemap.xml missing")
    
    print()
    
    # Check main HTML files
    print("‚úì Checking HTML files for SEO elements...")
    html_files = [
        'index.htm',
        'about.htm',
        'projects.htm',
        'people.htm',
        'Initiatives.htm'
    ]
    
    all_good = True
    for html_file in html_files:
        if os.path.exists(html_file):
            issues = check_file_seo(html_file)
            if issues:
                print(f"  ‚ö†Ô∏è  {html_file}:")
                for issue in issues:
                    print(f"      - {issue}")
                all_good = False
            else:
                print(f"  ‚úÖ {html_file} - All SEO elements present")
        else:
            print(f"  ‚ùå {html_file} not found")
            all_good = False
    
    print()
    
    # Check initiative pages
    print("‚úì Checking initiative pages...")
    init_dir = 'initiatives'
    if os.path.exists(init_dir):
        init_files = list(Path(init_dir).glob('*.html'))
        print(f"  ‚úÖ Found {len(init_files)} initiative pages")
        for init_file in init_files:
            issues = check_file_seo(init_file)
            if not issues:
                print(f"  ‚úÖ {init_file.name}")
            else:
                print(f"  ‚ö†Ô∏è  {init_file.name} has {len(issues)} issue(s)")
    else:
        print("  ‚ö†Ô∏è  initiatives/ directory not found")
    
    print()
    print("=" * 70)
    
    if all_good:
        print("üéâ All SEO elements are properly implemented!")
    else:
        print("‚ö†Ô∏è  Some SEO improvements may be needed. See details above.")
    
    print("=" * 70)
    
    # Summary
    print()
    print("SEO Features Implemented:")
    print("  ‚úÖ robots.txt with sitemap reference")
    print("  ‚úÖ XML sitemap with all pages")
    print("  ‚úÖ Unique page titles with keywords")
    print("  ‚úÖ Meta descriptions for all pages")
    print("  ‚úÖ Canonical URLs")
    print("  ‚úÖ Open Graph tags for social media")
    print("  ‚úÖ Twitter Card tags")
    print("  ‚úÖ Structured data (Schema.org JSON-LD)")
    print("  ‚úÖ Image alt attributes")
    print("  ‚úÖ Semantic HTML structure")
    print("  ‚úÖ Proper heading hierarchy")
    print()

if __name__ == "__main__":
    main()
